{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵分解\n",
    "代码来自 [OpenLearning4DeepRecsys](https://github.com/Leavingseason/OpenLearning4DeepRecsys/tree/master/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import data_reader \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(user_indices, item_indices, rank, ratings, user_cnt, item_cnt, lr, lamb, mu, init_value):\n",
    "    \n",
    "    W_user = tf.Variable(tf.truncated_normal([user_cnt, rank], stddev=init_value/math.sqrt(float(rank)), mean=0), \n",
    "                         name = 'user_embedding', dtype=tf.float32)\n",
    "    W_item = tf.Variable(tf.truncated_normal([item_cnt, rank], stddev=init_value/math.sqrt(float(rank)), mean=0), \n",
    "                         name = 'item_embedding', dtype=tf.float32)\n",
    "    \n",
    "    W_user_bias = tf.concat([W_user, tf.ones((user_cnt,1), dtype=tf.float32)], 1, name='user_embedding_bias')\n",
    "    W_item_bias = tf.concat([tf.ones((item_cnt,1), dtype=tf.float32), W_item], 1, name='item_embedding_bias')\n",
    "    \n",
    "    user_feature = tf.nn.embedding_lookup(W_user_bias, user_indices, name = 'user_feature')\n",
    "    item_feature = tf.nn.embedding_lookup(W_item_bias, item_indices, name = 'item_feature') \n",
    "    \n",
    "    preds = tf.add(tf.reduce_sum( tf.multiply(user_feature , item_feature) , 1), mu)\n",
    "    \n",
    "    square_error = tf.sqrt(tf.reduce_mean( tf.squared_difference(preds, ratings)))\n",
    "    loss = square_error + lamb*(tf.reduce_mean(tf.nn.l2_loss(W_user)) + tf.reduce_mean(tf.nn.l2_loss(W_item)))\n",
    "        \n",
    "    tf.summary.scalar('square_error', square_error)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    #tf.global_variables_initializer()\n",
    "    train_step = tf.train.GradientDescentOptimizer(lr).minimize(loss)   # tf.train.AdadeltaOptimizer(learning_rate=lr).minimize(loss)    #\n",
    "\n",
    "    return train_step, square_error, loss, merged_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_run(dataset,rank,user_cnt,item_cnt,lr,lamb,mu,n_eopch,batch_size,is_eval_on, init_value):\n",
    "    \n",
    "    user_indices =  tf.placeholder(tf.int32,[None])\n",
    "    item_indices =  tf.placeholder(tf.int32,[None])\n",
    "    ratings = tf.placeholder(tf.float32, [None])    \n",
    "\n",
    "    train_step, square_error, loss, merged_summary = build_model(user_indices, item_indices, rank, ratings, \n",
    "                                                                 user_cnt, item_cnt, lr, lamb, mu, init_value)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init) \n",
    "    \n",
    "    #print(sess.run(user_embeddings))\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(r'logs', sess.graph)\n",
    "    \n",
    "    n_instances = len(dataset.training_ratings_user)\n",
    "\n",
    "    best_train_rmse, best_test_rmse, best_eval_rmse = -1, -1, -1\n",
    "    best_eopch_idx = -1 \n",
    "    for ite in range(n_eopch):\n",
    "        #print(ite)\n",
    "        start = clock()\n",
    "        for i in range(n_instances//batch_size):\n",
    "            start_idx = i * batch_size \n",
    "            end_idx = start_idx + batch_size\n",
    "            cur_user_indices = dataset.training_ratings_user[start_idx:end_idx]\n",
    "            cur_item_indices = dataset.training_ratings_item[start_idx:end_idx]\n",
    "            cur_label = dataset.training_ratings_score[start_idx:end_idx]\n",
    "            \n",
    "            sess.run(train_step, { user_indices : cur_user_indices, item_indices : cur_item_indices, ratings : cur_label})  \n",
    "            \n",
    "        error_traing = sess.run(square_error, { user_indices : dataset.training_ratings_user, \n",
    "                                                item_indices : dataset.training_ratings_item, \n",
    "                                                ratings : dataset.training_ratings_score})\n",
    "        error_test = sess.run(square_error, { user_indices : dataset.test_ratings_user, \n",
    "                                              item_indices : dataset.test_ratings_item, \n",
    "                                              ratings : dataset.test_ratings_score})\n",
    "        if is_eval_on:\n",
    "            error_eval = sess.run(square_error, { user_indices : dataset.eval_ratings_user, \n",
    "                                                  item_indices : dataset.eval_ratings_item, \n",
    "                                                  ratings : dataset.eval_ratings_score})\n",
    "        else: \n",
    "            error_eval = -1\n",
    "            \n",
    "        if best_test_rmse<0 or best_test_rmse>error_test:\n",
    "            best_train_rmse, best_test_rmse, best_eval_rmse = error_traing,error_test, error_eval \n",
    "            best_eopch_idx = ite \n",
    "        else:\n",
    "            if ite - best_eopch_idx>10:\n",
    "                break \n",
    "            \n",
    "        loss_traing = sess.run(loss, { user_indices : dataset.training_ratings_user, item_indices : dataset.training_ratings_item, \n",
    "                                      ratings : dataset.training_ratings_score})\n",
    "        #loss_test = sess.run(loss, { user_feature : test_user_feature, item_feature : test_item_feature, ratings : test_label})\n",
    "        summary = sess.run(merged_summary, { user_indices : dataset.training_ratings_user, item_indices : dataset.training_ratings_item,\n",
    "                                      ratings : dataset.training_ratings_score})\n",
    "        train_writer.add_summary(summary, ite)\n",
    "        end = clock()\n",
    "        print(\"Iteration %d  RMSE(train): %f  RMSE(test): %f   RMSE(eval): %f   LOSS(train): %f  minutes: %f\" %\n",
    "              (ite, error_traing, error_test, error_eval, loss_traing, (end-start)/60))\n",
    "        \n",
    "    train_writer.close()\n",
    "    \n",
    "    return best_train_rmse, best_test_rmse, best_eval_rmse,best_eopch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_with_parameter(dataset,rank,lr,lamb,mu,n_eopch,batch_size,wt, init_value):\n",
    "    start = clock()\n",
    "    tf.reset_default_graph()\n",
    "    best_train_rmse, best_test_rmse, best_eval_rmse, best_eopch_idx = single_run(dataset,rank,dataset.n_user,dataset.n_item,\n",
    "                                                                                 lr,lamb,mu,n_eopch,batch_size,True, init_value)\n",
    "    end = clock()\n",
    "    wt.write('%d,%f,%f,%f,%d,%d,%f,%f,%f,%d,%f,%f\\n' %\n",
    "             (rank,lr,lamb,mu,n_eopch,batch_size,best_train_rmse, best_test_rmse, best_eval_rmse,best_eopch_idx,init_value,(end-start)/60))\n",
    "    wt.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_params():\n",
    "\n",
    "    dataset = data_reader.sparse_data_repos(10000,10005)\n",
    "    dataset.load_trainging_ratings(r'data/userbook_unique_compactid_train.txt')\n",
    "    dataset.load_test_ratings(r'data/userbook_unique_compactid_valid.txt')\n",
    "    dataset.load_eval_ratings(r'data/userbook_unique_compactid_test.txt')\n",
    "    log_file = r'BMF_log.csv'\n",
    "    \n",
    "    wt = open(log_file,'w')\n",
    "    rank = 16\n",
    "    lambs=[0.00003,0.00005,0.0001]\n",
    "    batch_sizes=[500]\n",
    "    n_eopch=2000\n",
    "    lrs=[0.1]\n",
    "    init_values = [0.01]\n",
    "    #mu=dataset.training_ratings_score.mean()\n",
    "    mu = np.asarray(dataset.training_ratings_score, dtype=np.float32).mean() \n",
    "    wt.write('rank,lr,lamb,mu,n_eopch,batch_size,best_train_rmse,best_test_rmse,best_eval_rmse,best_epoch,init_value,minutes\\n')\n",
    "    for lamb in lambs:\n",
    "        for lr in lrs:\n",
    "            for init_value in init_values:\n",
    "                for batch_size in batch_sizes:\n",
    "                    run_with_parameter(dataset,rank,lr,lamb,mu,n_eopch,batch_size,wt, init_value)\n",
    "    wt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    grid_search_params()\n",
    "    #run()\n",
    "    pass "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
